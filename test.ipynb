{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d791b990-f40e-482b-bce6-8b9b2302060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在Jupyter Notebook中运行启发式生成代码\n",
    "import argparse\n",
    "import os\n",
    "from src.pipeline.heuristic_generator import HeuristicGenerator\n",
    "from src.util.llm_client.get_llm_client import get_llm_client\n",
    "\n",
    "# 1. 定义参数（替代命令行输入）\n",
    "# 在这里修改参数值，相当于命令行中的各种选项\n",
    "problem = \"tsp\"  # 问题类型，如\"tsp\"、\"cvrp\"等\n",
    "smoke_test = True  # 是否进行冒烟测试，相当于命令行的-m\n",
    "llm_config_file = os.path.join(\"output\", \"llm_config\", \"azure_gpt_4o.json\")  # LLM配置文件路径\n",
    "source = \"llm\"  # 生成来源，可选\"llm\"、\"paper\"、\"related_problem\"\n",
    "paper_path = None  # 当source为\"paper\"时，指定论文路径\n",
    "related_problems = \"all\"  # 当source为\"related_problem\"时，指定相关问题\n",
    "reference_data = None  # 参考数据集路径\n",
    "\n",
    "# 2. 准备问题池（自动获取可用问题类型）\n",
    "problem_pool = [p for p in os.listdir(os.path.join(\"src\", \"problems\")) if p != \"base\"]\n",
    "if problem not in problem_pool:\n",
    "    raise ValueError(f\"问题类型'{problem}'不存在，可用问题类型：{problem_pool}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf12da41-8d1a-40a9-8846-faebe2bed5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cvrp', 'dposp', 'jssp', 'max_cut', 'mkp', 'tsp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7394c95c-6352-40c1-8868-8f29aa3dd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 初始化LLM客户端\n",
    "prompt_dir = os.path.join(\"src\", \"problems\", \"base\", \"prompt\")\n",
    "output_dir = os.path.join(\"output\", problem, \"generate_heuristic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e8c2b2-9524-43e6-8790-3052dede4059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'src\\\\problems\\\\base\\\\prompt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef24b209-a850-4844-91d8-05c4c2c396a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output\\\\tsp\\\\generate_heuristic'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4cc9ad9-7f91-48e5-924d-ac84abaa4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    problem_pool = [problem for problem in os.listdir(os.path.join(\"src\", \"problems\")) if problem != \"base\"]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Generate heuristic\")\n",
    "    parser.add_argument(\"-p\", \"--problem\", choices=problem_pool, required=True, help=\"Specifies the type of combinatorial optimization problem.\")\n",
    "    parser.add_argument(\"-m\", \"--smoke_test\", action='store_true', help=\"Optional flag to conduct a preliminary smoke test.\")\n",
    "    parser.add_argument(\"-l\", \"--llm_config_file\", type=str, default=os.path.join(\"output\", \"llm_config\", \"azure_gpt_4o.json\"), help=\"Path to the language model configuration file. Default is azure_gpt_4o.json.\")\n",
    "    parser.add_argument(\"-s\", \"--source\", choices=[\"llm\", \"paper\", \"related_problem\"], default=\"llm\", help=\"Source for generating heuristics: 'llm' for automated model generation, 'paper' for literature-based methods, 'related_problem' for adaptations from similar problems.\")\n",
    "    parser.add_argument(\"-pp\", \"--paper_path\", type=str, help=\"Specify the path to a LaTeX paper file or directory containing heuristic descriptions.\")\n",
    "    parser.add_argument(\"-r\", \"--related_problems\", type=str, default=\"all\", help=\"Comma-separated list of related problem domains to draw heuristic insights from.\")\n",
    "    parser.add_argument(\"-d\", \"--reference_data\", type=str, default=None, help=\"Optional path to reference datasets, used when generating heuristics tailored to specific data distributions.\")\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c249050-ffe5-4656-9b8d-b4c676e75c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api_endpoint = \"https://api.deepseek.com\", # 设置LLM（大语言模型）的API端点（需替换为实际地址）\n",
    "llm_api_key = \"sk-1795d95c9b4c4f3e9c54c80c1f5e5f31\",   # 设置LLM的API密钥（需替换为实际密钥）\n",
    "llm_model = \"deepseek-chat\", # 设置使用的LLM模型名称（需替换为实际模型名）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d79a0e3e-c331-4eb4-8b01-271963fc7983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat dumped to output\\tsp\\generate_heuristic\\background.txt\n",
      "Try to chat 1 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 2 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 3 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 4 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 5 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 6 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 7 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 8 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 9 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 10 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 11 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 12 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 13 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 14 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 15 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 16 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 17 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 18 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 19 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 20 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 21 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 22 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 23 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 24 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 25 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 26 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 27 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 28 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 29 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 30 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 31 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 32 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 33 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 34 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 35 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 36 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 37 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 38 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 39 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 40 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 41 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 42 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 43 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 44 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 45 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 46 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 47 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 48 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 49 time: Expecting value: line 1 column 1 (char 0)\n",
      "Try to chat 50 time: Expecting value: line 1 column 1 (char 0)\n",
      "Chat dumped to output\\tsp\\generate_heuristic\\error.txt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 5. 根据来源生成启发式算法\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# 从LLM生成\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     result \u001b[38;5;241m=\u001b[39m heuristic_generator\u001b[38;5;241m.\u001b[39mgenerate_from_llm(\n\u001b[0;32m     39\u001b[0m         reference_data\u001b[38;5;241m=\u001b[39mreference_data,\n\u001b[0;32m     40\u001b[0m         smoke_test\u001b[38;5;241m=\u001b[39msmoke_test\n\u001b[0;32m     41\u001b[0m     )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# 从论文生成（需指定paper_path）\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paper_path:\n",
      "File \u001b[1;32m~\\HeurAgenix-main\\src\\pipeline\\heuristic_generator.py:30\u001b[0m, in \u001b[0;36mHeuristicGenerator.generate_from_llm\u001b[1;34m(self, reference_data, smoke_test)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Generate available heuristic description\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_client\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate_from_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompt_dict)\n\u001b[1;32m---> 30\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_client\u001b[38;5;241m.\u001b[39mchat()\n\u001b[0;32m     31\u001b[0m heuristics \u001b[38;5;241m=\u001b[39m extract(response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheuristic\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_client\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheuristic_from_llm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\HeurAgenix-main\\src\\util\\llm_client\\base_llm_client.py:52\u001b[0m, in \u001b[0;36mBaseLLMClient.chat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# 若超过最大尝试次数，添加错误信息到对话历史并保存\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExceeded the maximum number of attempts\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\HeurAgenix-main\\src\\util\\llm_client\\base_llm_client.py:172\u001b[0m, in \u001b[0;36mBaseLLMClient.dump\u001b[1;34m(self, output_name)\u001b[0m\n\u001b[0;32m    170\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    173\u001b[0m         contents \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 图片用路径标识\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# 在Jupyter Notebook中运行启发式生成代码\n",
    "import argparse\n",
    "import os\n",
    "from src.pipeline.heuristic_generator import HeuristicGenerator\n",
    "from src.util.llm_client.get_llm_client import get_llm_client\n",
    "\n",
    "# 1. 定义参数（替代命令行输入）\n",
    "# 在这里修改参数值，相当于命令行中的各种选项\n",
    "problem = \"tsp\"  # 问题类型，如\"tsp\"、\"cvrp\"等\n",
    "smoke_test = True  # 是否进行冒烟测试，相当于命令行的-m\n",
    "llm_config_file = os.path.join(\"output\", \"llm_config\", \"azure_gpt_4o.json\")  # LLM配置文件路径\n",
    "source = \"llm\"  # 生成来源，可选\"llm\"、\"paper\"、\"related_problem\"\n",
    "paper_path = None  # 当source为\"paper\"时，指定论文路径\n",
    "related_problems = \"all\"  # 当source为\"related_problem\"时，指定相关问题\n",
    "reference_data = None  # 参考数据集路径\n",
    "\n",
    "# 2. 准备问题池（自动获取可用问题类型）\n",
    "problem_pool = [p for p in os.listdir(os.path.join(\"src\", \"problems\")) if p != \"base\"]\n",
    "if problem not in problem_pool:\n",
    "    raise ValueError(f\"问题类型'{problem}'不存在，可用问题类型：{problem_pool}\")\n",
    "\n",
    "# 3. 初始化LLM客户端\n",
    "prompt_dir = os.path.join(\"src\", \"problems\", \"base\", \"prompt\")\n",
    "output_dir = os.path.join(\"output\", problem, \"generate_heuristic\")\n",
    "\n",
    "# 创建输出目录（如果不存在）\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 获取LLM客户端\n",
    "llm_client = get_llm_client(llm_config_file, prompt_dir, output_dir)\n",
    "\n",
    "# 4. 初始化启发式生成器\n",
    "heuristic_generator = HeuristicGenerator(llm_client=llm_client, problem=problem)\n",
    "\n",
    "# 5. 根据来源生成启发式算法\n",
    "if source == \"llm\":\n",
    "    # 从LLM生成\n",
    "    result = heuristic_generator.generate_from_llm(\n",
    "        reference_data=reference_data,\n",
    "        smoke_test=smoke_test\n",
    "    )\n",
    "elif source == \"paper\":\n",
    "    # 从论文生成（需指定paper_path）\n",
    "    if not paper_path:\n",
    "        raise ValueError(\"当source为'paper'时，必须指定paper_path\")\n",
    "    result = heuristic_generator.generate_from_paper(\n",
    "        paper_path=paper_path,\n",
    "        reference_data=reference_data,\n",
    "        smoke_test=smoke_test\n",
    "    )\n",
    "elif source == \"related_problem\":\n",
    "    # 从相关问题迁移\n",
    "    if related_problems == \"all\":\n",
    "        related_problems_list = [p for p in problem_pool if p not in [\"base\", problem]]\n",
    "    else:\n",
    "        related_problems_list = related_problems.split(\",\")\n",
    "    \n",
    "    result = heuristic_generator.generate_from_reference(\n",
    "        related_problems=related_problems_list,\n",
    "        reference_data=reference_data,\n",
    "        smoke_test=smoke_test\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"未知的生成来源：{source}，可用来源：['llm', 'paper', 'related_problem']\")\n",
    "\n",
    "print(f\"启发式算法生成完成，结果保存至：{output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
